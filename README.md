# WorldWiseAI: Measuring Cultural Alignment in Large Language Models

## Overview
WorldWiseAI is a rigorous framework for evaluating **cultural alignment in Large Language Models (LLMs)** using Hofstede's cultural dimensions as an analytical scaffold. Instead of prompting LLMs with survey-style Likert questions (which produces shallow or unreliable results), WorldWiseAI uses **semantic inference** to analyze *how* an LLM reasons in ethically or culturally charged scenarios.

This approach produces:
- A **semantic Hofstede-like cultural profile** for each LLM response
- **Overall cultural alignment** scores (how closely a persona matches a target culture)
- **Dimension-level alignment** (which Hofstede dimensions influence that alignment)
- **Baseline cultural bias** (which culture an unprompted model resembles)
- **Cultural shift magnitude** (how strongly a cultural persona influences model reasoning)

---

## Table of Contents
1. [Motivation](#1-motivation)
2. [Methodology](#2-methodology)
3. [Experimental Setup](#3-experimental-setup)
4. [Results & Analysis](#4-results--analysis)
5. [Key Findings](#5-key-findings)
6. [Visualizations](#6-visualizations)
7. [Limitations](#7-limitations)
8. [Technical Details](#8-technical-details)

---

# 1. Motivation

LLMs increasingly serve global audiences‚Äîbut their reasoning may implicitly reflect cultural biases or norms tied to training data. Traditional methods (like directly asking Hofstede survey questions) fail because:

- LLMs produce **generic or memorized answers**
- Hofstede surveys rely on **personal lived experience**, which LLMs lack
- LLMs may answer based on **training-content stereotypes**, not reasoning

WorldWiseAI addresses these issues by shifting the evaluation from:

> **"What does the model *say* about culture?" ‚Üí "What cultural values emerge from its *reasoning*?"**

---

# 2. Methodology

WorldWiseAI measures cultural alignment in **three stages**:

## 2.1 Stage 1 ‚Äî Scenario-Based Elicitation

LLMs are given ethically ambiguous scenarios designed to expose culturally influenced decision-making. For each run, a model receives:

- The **scenario** (30 scenarios covering all 6 Hofstede dimensions)
- An optional **cultural persona prompt** (e.g., "As someone from India")
- Instructions to explain its reasoning
- Extraction of:
  - **Decision outcome** (Option A, B, or Decline)
  - **Top 5 guiding values**
  - **Explanation text**

This creates rich, semantically meaningful text for analysis.

---

## 2.2 Stage 2 ‚Äî Semantic Cultural Projection

The LLM's reasoning text (values + explanation + decision summary) is embedded using a sentence-transformer (all-MiniLM-L6-v2). This yields a semantic vector representing the decision-making style.

For each Hofstede dimension (IDV, PDI, MAS, UAI, LTO, IVR), the vector is compared to a curated set of:
- **High-dimension exemplars** (e.g., High Individualism)
- **Low-dimension exemplars** (e.g., Low Individualism)

Using cosine similarity:

```python
high_sim = cos(response, high_exemplars)
low_sim  = cos(response, low_exemplars)
ratio = (high_sim - low_sim) / (high_sim + low_sim)
score = tanh(ratio) * 2
```

This produces a **continuous score in the range [-2, +2]** for each Hofstede dimension.

üí° This is NOT Hofstede's 0‚Äì100 scale‚Äîbut a semantic projection onto the *same conceptual axes*. Hofstede country scores are normalized to the same [-2, +2] range to enable valid comparison.

**Output:** A 6-dimensional "semantic Hofstede profile" that characterizes model reasoning.

---

## 2.3 Stage 3 ‚Äî Cultural Alignment Metrics

From the semantic cultural profile, we compute several alignment metrics.

### A) Overall Cultural Alignment (0‚Äì10)
For each scenario, compare the model's inferred cultural vector with the target culture's normalized Hofstede vector:

- Take the **Euclidean distance** across the *scenario-relevant dimensions*
- Convert to a 0‚Äì10 similarity score:

```python
alignment = 10 - distance * 2.5
```

This yields a single holistic measure of cultural fit.

### B) Dimension-Level Alignment (0‚Äì10)
Individually assess how close the model is on each Hofstede dimension:

```python
score = 10 - |expected_dim - actual_dim| * 2.5
```

This reveals *which dimensions* contribute most to alignment or misalignment.

### C) Baseline Cultural Bias
Unprompted responses are averaged to form a baseline profile. Distance to each country's cultural vector reveals **which culture the model resembles by default**.

### D) Cultural Shift Magnitude
Comparing baseline values to persona-prompted values yields a **total variation distance (TVD)** that measures:
- How strongly the persona prompt influences the model
- Which cultures exert greatest or weakest shifts

---

# 3. Experimental Setup

## 3.1 Experiment Configuration

**Dataset Statistics:**
- **Total Responses:** 720
- **Models Tested:** 4 (GPT-4, Claude Sonnet, Gemini Flash, DeepSeek)
- **Cultures:** 6 (India, Japan, Mexico, UAE, US, + Baseline/unprompted)
- **Scenarios:** 30 (covering all 6 Hofstede dimensions)
- **Parse Success Rate:** 100%

**Scenarios Coverage:**
- **Individualism (IDV):** 5 scenarios
- **Power Distance (PDI):** 5 scenarios
- **Masculinity (MAS):** 5 scenarios
- **Uncertainty Avoidance (UAI):** 5 scenarios
- **Long-Term Orientation (LTO):** 5 scenarios
- **Indulgence (IVR):** 5 scenarios

Each (model √ó culture √ó scenario) combination was executed once, with caching to ensure consistency.

---

# 4. Results & Analysis

## 4.1 Overall Cultural Alignment

### Summary Scores (0‚Äì10 scale)

| Culture | Alignment Score | Std Dev | Interpretation |
|---------|----------------|---------|----------------|
| **India** | **7.71** | 1.09 | ‚úÖ Highest alignment - models most reliably emulate Indian reasoning |
| **US** | **6.49** | 1.14 | ‚ö†Ô∏è Moderate alignment - baseline bias helps |
| **Japan** | **6.40** | 1.51 | ‚ö†Ô∏è Moderate alignment - mixed dimension performance |
| **UAE** | **5.73** | 0.89 | ‚ö†Ô∏è Below average - challenging to emulate |
| **Mexico** | **5.22** | 0.75 | üî¥ Lowest alignment - most difficult culture |

**Mean Overall Alignment:** 6.31/10

### Key Insight
The model most reliably emulates **Indian cultural reasoning**, followed by US and Japan. UAE and Mexico prove significantly harder to emulate, suggesting:
- **Training data bias** toward certain cultural contexts
- **Semantic representation** of collectivist + long-term oriented values is stronger
- **Western individualism** (despite US being in training data) is not the dominant bias

---

## 4.2 Dimension-Level Alignment Analysis

### Mean Alignment by Culture and Dimension

| Culture | IDV | IVR | LTO | MAS | PDI | UAI |
|---------|-----|-----|-----|-----|-----|-----|
| **India** | **9.58** | 5.52 | **8.89** | 7.31 | 6.23 | **8.80** |
| **Japan** | **9.58** | 6.91 | 5.91 | 4.98 | **9.79** | 3.98 |
| **UAE** | 6.05 | 6.74 | 5.07 | **9.71** | 5.12 | 4.96 |
| **US** | 5.24 | 7.07 | 4.75 | 7.63 | 7.50 | **8.39** |
| **Mexico** | 6.15 | 5.58 | 5.27 | 6.08 | 5.22 | 3.97 |

### Overall Dimension Difficulty

| Dimension | Mean Score | Difficulty Rating |
|-----------|------------|-------------------|
| **Individualism (IDV)** | 7.32 | üü¢ Easiest |
| **Masculinity (MAS)** | 7.14 | üü¢ Easy |
| **Power Distance (PDI)** | 6.77 | üü° Moderate |
| **Indulgence (IVR)** | 6.36 | üü° Moderate |
| **Uncertainty Avoidance (UAI)** | 6.02 | üî¥ Hard |
| **Long-Term Orientation (LTO)** | 5.98 | üî¥ Hardest |

### Interpretation by Culture

**India (7.71):**
- ‚úÖ Exceptional: IDV (9.58), LTO (8.89), UAI (8.80)
- ‚ö†Ô∏è Moderate: MAS (7.31), PDI (6.23), IVR (5.52)
- **Insight:** Models excel at Indian individualism patterns and long-term planning values

**Japan (6.40):**
- ‚úÖ Exceptional: IDV (9.58), PDI (9.79)
- üî¥ Poor: UAI (3.98), MAS (4.98)
- **Insight:** Strong on hierarchical respect, weak on uncertainty management and achievement orientation

**UAE (5.73):**
- ‚úÖ Strong: MAS (9.71)
- üî¥ Weak: LTO (5.07), PDI (5.12), UAI (4.96)
- **Insight:** Achievement values captured, but long-term and hierarchical nuances missed

**US (6.49):**
- ‚úÖ Strong: UAI (8.39), MAS (7.63), PDI (7.50)
- üî¥ Weak: LTO (4.75), IDV (5.24)
- **Insight:** Paradoxically weak on individualism despite US cultural stereotype

**Mexico (5.22):**
- üî¥ Consistently weak across all dimensions
- Worst: UAI (3.97), PDI (5.22)
- **Insight:** Most challenging culture to emulate; requires better training data

---

## 4.3 Baseline Cultural Bias

### Unprompted Model Resembles:

**Distance from Baseline (Lower = Closer)**

| Culture | Distance | Interpretation |
|---------|----------|----------------|
| **India** | **1.075** | ‚úÖ Closest match - inherent bias toward Indian values |
| **US** | 1.367 | ‚ö†Ô∏è Moderate similarity |
| **Japan** | 1.548 | ‚ö†Ô∏è Moderate similarity |
| **UAE** | 1.636 | üî¥ Distant |
| **Mexico** | 1.930 | üî¥ Most distant |

### Baseline Value Distribution

**Top 3 Values (Unprompted):**
1. **Future Planning** (37 occurrences)
2. **Achievement & Success** (31 occurrences)
3. **Family Harmony** (26 occurrences)

**‚ö†Ô∏è Key Finding:** The model's default reasoning (without cultural prompting) exhibits:
- Strong **collectivist** tendencies (Family Harmony)
- High **long-term orientation** (Future Planning)
- Moderate **achievement focus** (Success-oriented)

This suggests the baseline is closer to **Indian/Asian collectivist values** rather than Western individualism, contrary to common assumptions about English-language LLM biases.

---

## 4.4 Model Performance Comparison

### Overall Performance by Model

| Model | Alignment | Consistency | Differentiation | Stereotype Score |
|-------|-----------|-------------|-----------------|------------------|
| **DeepSeek** | **6.39** | 10.0 | 0.0 | 7.95 |
| **Claude Sonnet** | 6.34 | 10.0 | 0.0 | 6.98 |
| **GPT-4** | 6.30 | 10.0 | 0.0 | **8.53** |
| **Gemini** | 6.19 | 10.0 | 0.0 | 6.77 |

### Statistical Significance

**ANOVA Results:**
- **F-statistic:** 0.534
- **p-value:** 0.659
- **Conclusion:** ‚ùå No significant difference between models (p ‚â• 0.05)

**Interpretation:**
- All models perform **remarkably similarly** on cultural alignment
- Differences are negligible (Cohen's d < 0.15 for all pairwise comparisons)
- **Stereotype scores** show significant variance (p < 0.001)
  - GPT-4 uses most stereotypes (8.53)
  - Gemini uses fewest stereotypes (6.77)

---




## 4.5 Cultural Shift Magnitude

**Understanding TVD:** Total Variation Distance measures how much the *distribution of values cited* changes between baseline and prompted responses. This is DIFFERENT from Hofstede dimensional similarity.

### Actual Results

**Cultures Ranked by Shift Magnitude (TVD):**

| Rank | Culture | TVD | Interpretation |
|------|---------|-----|----------------|
| 1 | **Japan** | 47.81% | Largest shift - most dramatic value redistribution |
| 2 | **India** | 46.45% | Very large shift - explicit persona activates distinct values |
| 3 | **UAE** | 44.95% | Large shift |
| 4 | **Mexico** | 43.14% | Large shift |
| 5 | **US** | 23.83% | **Smallest shift** - baseline already uses similar values |

**Average Shift:** 41.24%

### Key Value Shifts by Culture

**US (23.83% TVD - Smallest):**
- ‚Üë Achievement & Success: +8.7%
- ‚Üë Personal Autonomy: +5.5%
- ‚Üì Stability & Security: -2.7%

**India (46.45% TVD - Second Largest):**
- ‚Üë Family Harmony: +12.6% (from 26 ‚Üí 71 mentions)
- ‚Üë Stability & Security: +9.6%
- ‚Üë Respect for Authority: +7.4%
- ‚Üì Personal Autonomy: -6.4%

**Japan (47.81% TVD - Largest):**
- ‚Üë Respect for Authority: +10.1%
- ‚Üë Stability & Security: +7.5%
- ‚Üë Family Harmony: +7.2%
- ‚Üë Perseverance & Patience: +7.1%
- ‚Üì Personal Autonomy: -6.7%

**Mexico (43.14% TVD):**
- ‚Üë Family Harmony: +17.8% (largest single value shift)
- ‚Üë Respect for Authority: +6.7%
- ‚Üì Achievement & Success: -5.5%

**UAE (44.95% TVD):**
- ‚Üë Family Harmony: +12.5%
- ‚Üë Respect for Authority: +9.0%
- ‚Üë Stability & Security: +7.0%
- ‚Üë Tradition & Heritage: +5.7%

### Critical Insight: The Paradox Resolved

**At first glance, this seems contradictory:**
- Baseline is closest to India in Hofstede space (distance: 1.075)
- But India prompting causes second-largest value shift (TVD: 46.45%)
- Meanwhile US is farther from baseline (distance: 1.367)
- But US prompting causes smallest value shift (TVD: 23.83%)

**The Resolution - Two Different Metrics:**

1. **Hofstede Dimensional Distance** measures similarity in the 6-dimensional cultural space
   - Baseline scores similarly to India on IDV, PDI, MAS, UAI, LTO, IVR dimensions

2. **TVD (Value Distribution Shift)** measures change in which specific values are cited and how often
   - Baseline achieves its dimensional scores through a DIFFERENT vocabulary of values

**Why US Has Small TVD:**
- Baseline already emphasizes Achievement & Success (#2 value, 31 mentions)
- Baseline already uses individualist, autonomy-oriented language
- US prompting just tweaks the existing value distribution (+8.7% Achievement)
- The baseline "speaks US value language" even if dimensionally different

**Why India Has Large TVD:**
- Baseline's dimensional similarity to India is achieved through different value combinations
- India prompting activates STEREOTYPICALLY INDIAN value language
- Family Harmony increases dramatically: 26 ‚Üí 71 mentions (nearly 3x increase!)
- Explicit cultural persona causes shift to more collectivist vocabulary
- The model must change WHAT it talks about, not just HOW MUCH

### Interpretation

**The small US shift suggests:**
- Baseline training data already contains US-centric value vocabulary
- "Neutral" language in training is actually US-inflected
- US prompting doesn't require fundamental value reframing

**The large collectivist culture shifts suggest:**
- Baseline uses individualist vocabulary to achieve its dimensional scores
- Explicit cultural personas trigger shift to collectivist value language
- India, Japan, Mexico, UAE prompting requires more dramatic value reframing
- The model must actively suppress individualist values and elevate collectivist ones

**Key Takeaway:**
TVD reveals that the baseline's "closeness to India" (in dimensional space) is somewhat superficial. When explicitly prompted with Indian cultural identity, the model must still make substantial changes to its value vocabulary and emphasis patterns. The US requires minimal change because the baseline already uses US-compatible value language, even if the dimensional profile differs.

---
---

## 4.6 Scenario Analysis

### Performance by Scenario Category

| Category | Mean Alignment | Std Dev | Difficulty |
|----------|----------------|---------|------------|
| **Social Situations** | **6.97** | 1.59 | üü¢ Easiest |
| **Career & Competition** | 6.86 | 0.73 | üü¢ Easy |
| **Career & Work Culture** | 6.81 | 0.81 | üü¢ Easy |
| **Family & Obligations** | 6.70 | 1.25 | üü° Moderate |
| **Work & Wellbeing** | 6.58 | 0.86 | üü° Moderate |
| **Career & Work-Life** | 6.47 | 0.89 | üü° Moderate |
| **Family & Relationships** | 6.46 | 1.38 | üü° Moderate |
| **Social & Community** | 6.45 | 0.70 | üü° Moderate |
| **Education & Development** | 5.55 | 1.88 | üî¥ Hard |
| **Career & Finance** | **5.35** | 2.03 | üî¥ Hardest |

### Most Difficult Scenarios

**Top 5 Hardest Scenarios (Lowest Alignment):**

| Scenario | Mean Score | Std Dev | Primary Dimensions |
|----------|------------|---------|-------------------|
| **LTO001** | 5.35 | 2.03 | Long-Term Orientation, Finance |
| **LTO004** | 5.55 | 1.88 | Long-Term Orientation, Education |
| **LTO005** | 5.88 | 1.73 | Long-Term Orientation, Projects |
| **UAI002** | 5.88 | 1.73 | Uncertainty Avoidance |
| **UAI004** | 6.28 | 1.87 | Uncertainty Avoidance |

**Insight:** Scenarios involving **Long-Term Orientation (LTO)** and **Uncertainty Avoidance (UAI)** are consistently the most challenging across all models and cultures.

### Easiest Scenarios

**Top 5 Easiest Scenarios (Highest Alignment):**

| Scenario | Mean Score | Std Dev | Primary Dimensions |
|----------|------------|---------|-------------------|
| **PDI005** | 6.97 | 1.59 | Power Distance |
| **PDI001** | 6.97 | 1.57 | Power Distance |
| **PDI003** | 6.88 | 1.66 | Power Distance |
| **MAS001** | 6.86 | 0.73 | Masculinity |
| **MAS005** | 6.81 | 0.81 | Masculinity |

**Insight:** Scenarios involving **Power Distance (PDI)** and **Masculinity (MAS)** are easiest, suggesting models better understand hierarchical relationships and achievement-oriented values.

---

## 4.7 Decision Pattern Analysis

### Overall Decision Distribution

| Decision | Count | Percentage |
|----------|-------|------------|
| **Option A** | 389 | 54.0% |
| **Option B** | 322 | 44.7% |
| **Decline** | 9 | 1.2% |

### Decision Patterns by Culture

| Culture | Option A | Option B | Decline |
|---------|----------|----------|---------|
| **US** | **60.8%** | 38.3% | 0.8% |
| **Baseline** | 56.7% | 42.5% | 0.8% |
| **India** | 53.3% | 45.8% | 0.8% |
| **UAE** | 51.7% | 46.7% | 1.7% |
| **Japan** | 51.7% | 45.8% | 2.5% |
| **Mexico** | 50.0% | 49.2% | 0.8% |

**Decision Diversity (Entropy):**
- **Highest diversity:** Japan (0.791)
- **Lowest diversity:** US (0.710)

**Interpretation:**
- **US prompts** lead to more decisive, less balanced choices
- **Japan prompts** create most diverse, nuanced decision patterns
- **Baseline** resembles US more than other cultures

### Decision Patterns by Model

| Model | Option A | Option B | Decline |
|-------|----------|----------|---------|
| **GPT-4** | **66.1%** | 32.8% | 1.1% |
| **Gemini** | 56.7% | 42.8% | 0.6% |
| **DeepSeek** | 47.8% | 48.9% | 3.3% |
| **Claude Sonnet** | 45.6% | **54.4%** | 0.0% |

**Interpretation:**
- **GPT-4** is most decisive, favoring Option A heavily
- **Claude Sonnet** shows opposite bias, preferring Option B
- **DeepSeek** is most balanced but most likely to decline
- **Gemini** falls in the middle

---

## 4.8 Value Pattern Analysis

### Top Values by Culture

**India:**
1. Family Harmony (71)
2. Stability & Security (51)
3. Future Planning (47)

**Japan:**
1. Family Harmony (52)
2. Future Planning (44)
3. Stability & Security (43)

**Mexico:**
1. Family Harmony (86)
2. Stability & Security (32)
3. Future Planning (32)

**UAE:**
1. Family Harmony (70)
2. Future Planning (44)
3. Stability & Security (42)

**US:**
1. Achievement & Success (61)
2. Personal Autonomy (39)
3. Future Planning (35)

**Baseline:**
1. Future Planning (37)
2. Achievement & Success (31)
3. Family Harmony (26)

### Cross-Cultural Value Patterns

**Universal Themes:**
- **Family Harmony** dominates in collectivist cultures (India, Mexico, UAE, Japan)
- **Future Planning** appears in top 3 for all cultures
- **Stability & Security** is universal concern

**Cultural Distinctiveness:**
- **US** uniquely emphasizes Achievement & Personal Autonomy
- **Mexico** shows strongest Family Harmony emphasis (86 mentions)
- **India** balances collectivism with future orientation

---

# 5. Key Findings

## 5.1 Major Discoveries

### 1. **Unexpected Baseline Bias**
- Models exhibit inherent bias toward **Indian cultural values**, not Western/US values
- Unprompted reasoning emphasizes: Family Harmony, Future Planning, Collectivism
- This contradicts common assumptions about English-language LLM training biases

### 2. **Dimension Difficulty Hierarchy**
- **Easy:** Individualism (IDV), Masculinity (MAS)
- **Moderate:** Power Distance (PDI), Indulgence (IVR)
- **Hard:** Uncertainty Avoidance (UAI), Long-Term Orientation (LTO)

### 3. **Model Convergence**
- All models perform statistically identically on cultural alignment
- Differences lie in **stereotyping behavior**, not alignment quality
- GPT-4 uses most stereotypes, Gemini uses fewest

### 4. **Cultural Emulation Difficulty**
- **Easiest:** India (7.71/10)
- **Hardest:** Mexico (5.22/10)
- Gap of 2.5 points suggests significant training data imbalances

### 5. **Cultural Shift Patterns**
- US cultural prompts cause smallest value distribution shift (TVD: 23.83%)
- Japan/India prompts cause largest shifts (TVD: 47.81%, 46.45%)
- Paradox resolved: Baseline is dimensionally India-like but lexically US-like
- US requires minimal shift because baseline already uses US value vocabulary (Achievement, Personal Autonomy)
- Collectivist cultures require dramatic vocabulary reframing despite dimensional similarity
- TVD measures value vocabulary shift, not Hofstede dimensional distance

## 5.2 Implications

**For LLM Developers:**
- Need better representation of Mexican and UAE cultural contexts in training data
- UAI and LTO dimensions require targeted improvement
- Stereotype reduction more important than alignment improvement

**For LLM Users:**
- Be aware that "neutral" prompts likely reflect Indian/Asian collectivist values
- Cultural personas have varying effectiveness (India works best, Mexico worst)
- Models struggle with long-term planning and uncertainty management across cultures

**For Researchers:**
- Semantic projection approach successfully captures cultural nuances
- Hofstede framework remains relevant for AI evaluation
- Cross-cultural variance is more significant than cross-model variance

---

# 6. Visualizations

All visualizations are generated from `visualizer.py` using results from the latest experiment run.

## 6.1 Baseline Cultural Bias

![Baseline Comparison](baseline_comparison.png)

*Figure 1 ‚Äî Baseline (unprompted) decision distribution and top values. Shows the inherent value bias before any cultural steering. Notice the prominence of "Future Planning" and "Family Harmony" suggesting collectivist orientation.*

---

## 6.2 Cultural Alignment by Model and Culture

![Cultural Alignment by Model](cultural_alignment_by_model.png)

*Figure 2 ‚Äî Overall cultural alignment scores by model and culture with error bars. India shows highest alignment (7.71), while Mexico shows lowest (5.22). Models cluster tightly with no significant performance differences.*

---

## 6.3 Cultural Shift Magnitude

![Cultural Shift Magnitude](cultural_shift_magnitude.png)

*Figure 3 ‚Äî Total Variation Distance (TVD) showing how strongly each cultural persona shifts the model from baseline. India and Japan create largest shifts, US creates smallest (model already close to US baseline).*

---

## 6.4 Category Performance

![Category Performance](category_performance.png)

*Figure 4 ‚Äî Mean alignment scores by scenario category. Social Situations (6.97) are easiest, while Career & Finance (5.35) are hardest. Shows clear category-level difficulty patterns.*

---

## 6.5 Scenario Difficulty Ranking

![Scenario Difficulty](scenario_difficulty.png)

*Figure 5 ‚Äî Individual scenario difficulty ranking. Long-Term Orientation (LTO) scenarios consistently rank as most difficult, followed by Uncertainty Avoidance (UAI) scenarios.*

---

## 6.6 Decision Distribution by Culture

![Decision Distribution](decision_distribution.png)

*Figure 6 ‚Äî Stacked bar chart showing how often each culture chooses Option A, Option B, or Decline. US shows strongest preference for Option A (60.8%), while Mexico shows most balance (50/49).*

---

## 6.7 Decision Patterns by Model

![Decision Patterns](decision_patterns.png)

*Figure 7 ‚Äî Decision patterns per model. GPT-4 heavily favors Option A (66.1%), Claude Sonnet favors Option B (54.4%), DeepSeek is most balanced but most likely to decline (3.3%).*

---

## 6.8 Value Frequencies by Culture

![Value Frequency](value_frequency.png)

*Figure 8 ‚Äî Top values by culture shown as horizontal bar chart. Mexico shows strongest "Family Harmony" emphasis (86), US uniquely prioritizes "Achievement & Success" (61).*

---

## 6.9 Stereotype Scores by Model and Culture

![Stereotype Scores](stereotype_scores.png)

*Figure 9 ‚Äî Box plots showing distribution of human-rated stereotype scores. GPT-4 shows highest stereotyping (8.53 mean), Gemini shows lowest (6.77). Significant variance across models (p < 0.001).*

---

## 6.10 Model Comparison Radar

![Model Comparison Radar](model_comparison_radar.png)

*Figure 10 ‚Äî Multi-dimensional radar plot comparing models across Cultural Alignment, Stereotyping (inverted), Consistency, and Differentiation. Shows models cluster tightly on most metrics except stereotyping.*

---

## 6.11 Differentiation Heatmap

![Differentiation Heatmap](differentiation_heatmap.png)

*Figure 11 ‚Äî Heatmap showing how well each model differentiates between cultures. Darker colors indicate stronger differentiation. Shows models struggle equally across all cultures (all zero differentiation).*

---

# 7. Limitations

## 7.1 Methodological Limitations

1. **Hofstede Framework Constraints**
   - Hofstede scores are **approximate anchors**, not absolute truth
   - Framework developed 50+ years ago may not capture modern cultural nuances
   - Binary (high/low) exemplars may oversimplify cultural spectrums

2. **Semantic Projection Approximations**
   - Semantic embeddings capture **orientation**, not **survey magnitude**
   - [-2, +2] scale is normalized projection, not raw Hofstede scores
   - Cosine similarity assumes linear cultural dimensions

3. **Persona Prompting Limitations**
   - Measures **expressed reasoning**, not **true cultural identity**
   - LLMs lack lived experience and authentic cultural grounding
   - Cultural personas may activate stereotypes rather than genuine reasoning patterns

4. **Data Coverage Gaps**
   - Some cultures (UAE) lack direct Hofstede LTO/IVR data (use regional proxies)
   - 30 scenarios may not cover full cultural spectrum
   - Limited to 5 cultures + baseline (many cultures not represented)

## 7.2 Technical Limitations

1. **Model Selection**
   - Only tested 4 models (many other LLMs exist)
   - All models are frontier-class (no smaller or older models)
   - Single run per (model √ó culture √ó scenario) combination

2. **Evaluation Metrics**
   - Stereotype scoring is subjective (human-rated)
   - Consistency metric all 10.0 (needs more sensitive measure)
   - Differentiation metric all 0.0 (needs refinement)

3. **Sample Size**
   - 720 total responses (reasonable but not massive)
   - 30 scenarios per culture (could be expanded)
   - Single evaluator for stereotype scoring (no inter-rater reliability)

## 7.3 Interpretation Limitations

1. **Causality Claims**
   - Cannot prove *why* models exhibit certain biases
   - Training data composition is proprietary/unknown
   - Cannot distinguish between data bias vs. architectural bias

2. **Generalization**
   - Results may not generalize to:
     - Newer model versions
     - Different prompt formats
     - Real-world deployment contexts
     - Non-English languages

3. **Practical Application**
   - Framework measures alignment, not **appropriateness** for specific use cases
   - High alignment doesn't guarantee ethical or beneficial behavior
   - Cultural stereotypes vs. authentic reasoning remains ambiguous

---

# 8. Technical Details

## 8.1 System Architecture

**Pipeline Components:**

1. **Scenario Generator** (`scenarios.py`)
   - 30 pre-defined scenarios covering 6 Hofstede dimensions
   - Each scenario presents ethically ambiguous choice
   - Scenarios tagged with primary/secondary dimensions

2. **Prompt Constructor** (`prompt_constructor.py`)
   - Combines scenario with optional cultural persona
   - Instructs model to provide: decision, values, explanation
   - Standardized format across all models

3. **LLM Interface** (`llm_interface.py`)
   - Unified API for multiple LLM providers
   - Response caching for consistency
   - Error handling and retry logic

4. **Response Parser** (`response_parser.py`)
   - Extracts structured data from LLM responses
   - Validates decision format and value lists
   - 100% parse success rate in latest run

5. **Evaluator** (`evaluator.py`)
   - Semantic embedding using sentence-transformers
   - Hofstede dimension projection via cosine similarity
   - Cultural alignment scoring

6. **Analyzer** (`analyze.py`)
   - Statistical significance testing (ANOVA, t-tests)
   - Dimension-level and scenario-level analysis
   - Value pattern extraction

7. **Visualizer** (`visualizer.py`)
   - Generates 11 publication-quality visualizations
   - Radar plots, heatmaps, bar charts, box plots
   - Consistent styling and color schemes

## 8.2 Dependencies

```txt
openai>=1.0.0
anthropic>=0.8.0
google-generativeai>=0.3.0
sentence-transformers>=2.2.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
scipy>=1.10.0
```

## 8.3 Hofstede Dimension Definitions

| Dimension | High Score Indicates | Low Score Indicates |
|-----------|---------------------|---------------------|
| **IDV** (Individualism) | Self-reliance, personal goals | Collective welfare, group harmony |
| **PDI** (Power Distance) | Accept hierarchy, defer to authority | Egalitarian, question authority |
| **MAS** (Masculinity) | Achievement, competition, success | Cooperation, modesty, quality of life |
| **UAI** (Uncertainty Avoidance) | Need structure, avoid ambiguity | Comfortable with uncertainty |
| **LTO** (Long-Term Orientation) | Future planning, perseverance | Tradition, short-term results |
| **IVR** (Indulgence) | Gratification, leisure, freedom | Restraint, strict norms, duties |

## 8.4 Country Profiles (Normalized [-2, +2] scale)

| Country | IDV | PDI | MAS | UAI | LTO | IVR |
|---------|-----|-----|-----|-----|-----|-----|
| **US** | 1.80 | -0.80 | 1.24 | -0.92 | -0.52 | 1.36 |
| **India** | 0.96 | 1.54 | 1.12 | -0.80 | 1.02 | -0.52 |
| **Japan** | 0.92 | 1.08 | 1.90 | 1.84 | 1.76 | -0.86 |
| **Mexico** | -0.60 | 1.62 | 1.04 | 1.64 | -0.48 | -0.38 |
| **UAE** | 0.70 | 1.80 | 1.06 | -0.20 | 0.72 | -0.48 |

---

# 9. Future Work

## 9.1 Immediate Extensions

1. **Expand Model Coverage**
   - Test Llama 3, Mistral, Qwen, and other open-source models
   - Include older model versions for longitudinal analysis
   - Test smaller models (7B, 13B parameters)

2. **Expand Cultural Coverage**
   - Add African, Middle Eastern, South American cultures
   - Test within-culture variation (rural vs urban, regions)
   - Include minority cultures and diaspora communities

3. **Improve Scenarios**
   - Increase to 50-100 scenarios for better coverage
   - Add multi-dimensional scenarios (conflicting values)
   - Include culturally-specific scenarios (not Western-centric)

## 9.2 Methodological Enhancements

1. **Multi-Rater Evaluation**
   - Multiple human evaluators for stereotype scoring
   - Calculate inter-rater reliability
   - Use consensus scoring for ground truth

2. **Longitudinal Analysis**
   - Track cultural alignment changes across model updates
   - Measure impact of RLHF and fine-tuning
   - Test temporal stability of cultural personas

3. **Alternative Frameworks**
   - Test other cultural frameworks (Schwartz, Trompenaars, GLOBE)
   - Develop AI-native cultural dimension framework
   - Combine multiple frameworks for richer analysis

## 9.3 Real-World Applications

1. **Fairness Auditing**
   - Use framework for AI fairness certification
   - Detect and quantify cultural bias in production systems
   - Monitor alignment drift over time

2. **Culturally-Aware Fine-Tuning**
   - Use alignment scores to guide fine-tuning
   - Create culturally-balanced training datasets
   - Develop culture-specific model variants

3. **User Interface Adaptation**
   - Detect user's cultural context from conversation
   - Dynamically adjust model behavior
   - Provide cultural explanations for reasoning

---

# 10. Conclusion

WorldWiseAI demonstrates that **semantic projection onto cultural dimensions** provides a rigorous, scalable method for measuring cultural alignment in LLMs. Key contributions include:

1. **Novel Methodology:** Moving beyond survey questions to semantic inference of cultural values from reasoning text

2. **Comprehensive Framework:** End-to-end pipeline from scenario design ‚Üí semantic projection ‚Üí alignment metrics ‚Üí visualization

3. **Actionable Insights:**
   - Models exhibit unexpected collectivist bias (closest to India)
   - Long-Term Orientation and Uncertainty Avoidance are hardest dimensions
   - Cross-model performance is statistically identical
   - Mexico and UAE need better training data representation

4. **Open Questions:**
   - Why does baseline resemble India more than US?
   - How can we improve LTO and UAI dimension alignment?
   - What causes model-specific stereotyping patterns?
   - How to balance cultural authenticity vs. harmful stereotypes?

This framework provides researchers and practitioners with tools to understand, measure, and ultimately improve cultural fairness in AI systems serving global populations.

---

## Citation

If you use WorldWiseAI in your research, please cite:

```bibtex
@software{worldwiseai2024,
  title={WorldWiseAI: Measuring Cultural Alignment in Large Language Models},
  author={[Your Name]},
  year={2024},
  url={https://github.com/yourusername/worldwiseai}
}
```

---

## License

[Specify your license here]

---

## Contact

[Your contact information]

---

**Last Updated:** November 20, 2024
**Dataset Version:** results_20251120_140046
**Total Responses Analyzed:** 720